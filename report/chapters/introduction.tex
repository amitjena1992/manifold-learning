\chapter{Introduction}

Throughout the years, machine learning techniques have grown popular between both academical and the corporative sectors. Their vast applications and promising results \cite{brownlee} indubitably contributed to our current scenario where not only computer scientists or mathematicians, but engineers, psychologists and many other groups have taken interest \cite{baldi2001bioinformatics} on how to adapt and apply these studies to their own problems.

Machine learning can help us to understand large amount of data and take decisions based on it. To achieve this, however, we must first find ways to effectively (and efficiently) extract the information that lies within the data.

Many different machine learning algorithms have been developed during the this and the last century. Between those, many could successfully generalize low dimensional data. \cite{wang2012geometric} In the other hand, problems of our world are often too complex and may be represented by high dimensional data. For example, images, sounds or text documents can be expressed as vectors of the $\mathbb{R}^n$, where each element corresponds to a pixel, wave signal or character, respectively. When analyzing these problems, we observed that many of the algorithms would often become unstable. \textbf{Dimensionality reduction} (or DR) then quickly became a key concept for minimizing the data size while maintaining its meaning.

Finally, dimensionality reduction has evolved into an extensive area. Nowadays, DR is not only applied to reduce the data size, specifically, but often employed in data visualization, noise reduction and for many other purposes.
