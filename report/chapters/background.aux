\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{ren2010}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Relevant Background}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Data set}{3}{section.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{Example of a canonical data set}{3}{section.2.1}}
\newlabel{irisdataset}{{2.1}{3}{Example of a canonical data set}{section.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The first three samples of the Iris flower data set \footnotemark .\relax }}{4}{table.caption.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Data set as a collection of vectors in the $\mathbb  {R}^n$}{4}{subsection.2.1.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces The first three samples of the Indian Liver Patient Dataset (ILPD) \footnotemark \relax }}{4}{table.caption.9}}
\citation{cay2005}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The data set ILPD's samples mapped onto the $\mathbb  {R}^n$, where each of its features is an axis in one graph, except for $S \mathrel {\mathrel {\mathop :}\mkern -1.2mu=}\{1, 2\}$, which was represented by the vertices' colors.\relax }}{5}{figure.caption.10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:disp_ilpd}{{2.1}{5}{The data set ILPD's samples mapped onto the $\mathbb {R}^n$, where each of its features is an axis in one graph, except for $S \coloneqq \{1, 2\}$, which was represented by the vertices' colors.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Modern Problems and Applications}{5}{subsection.2.1.2}}
\citation{gho2006}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces The Leukemia data set, with 72 samples and 7130 features \footnotemark .\relax }}{6}{table.caption.11}}
\newlabel{tb:ds_leukemia}{{2.3}{6}{The Leukemia data set, with 72 samples and 7130 features \protect \footnotemark .\relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Probability Theory}{6}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Feature Normalization and Standardization}{6}{subsection.2.2.1}}
\citation{ross2010introductory}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Centering Matrix}{7}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Variance}{7}{subsection.2.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Covariance}{8}{subsection.2.2.4}}
\@writefile{toc}{\contentsline {paragraph}{Covariance Matrix of Features in a Centered Data Set}{8}{remark.2.2.1}}
\citation{cox2001}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Numerical Analysis}{9}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Eigenvalues and Eigenvectors of a Matrix}{9}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Spectral Decomposition of a Matrix}{9}{subsection.2.3.2}}
\citation{gan2008}
\citation{lee2009}
\citation{lee2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Singular Value Decomposition}{10}{subsection.2.3.3}}
\newlabel{sec:svd}{{2.3.3}{10}{Singular Value Decomposition}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Decomposition of Symmetric Matrices}{10}{subsection.2.3.3}}
\newlabel{th:svd-aat}{{2.3.3}{10}{Decomposition of Symmetric Matrices}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Topology}{10}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Manifolds}{10}{subsection.2.4.1}}
\citation{lee2002}
\citation{lee2002}
\citation{stereo_proj}
\citation{stereo_proj}
\citation{stereo_proj}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The Torus, often studied in topology, it is a manifold that can be mapped to the $\mathbb  {R}^2$ \footnotemark .\relax }}{11}{figure.caption.12}}
\newlabel{fig:mani_torus}{{2.2}{11}{The Torus, often studied in topology, it is a manifold that can be mapped to the $\mathbb {R}^2$ \protect \footnotemark .\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{Charts}{11}{figure.caption.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Charts mapping four regions of a circle to different open sets \footnotemark .\relax }}{11}{figure.caption.13}}
\newlabel{fig:mani_charts}{{2.3}{11}{Charts mapping four regions of a circle to different open sets \protect \footnotemark .\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{Atlas}{11}{figure.caption.13}}
\citation{burris2011course}
\citation{berge1973}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Stereographic projection applied to Earth \cite  {stereo_proj}.\relax }}{12}{figure.caption.14}}
\newlabel{fig:stereographic_earth}{{2.4}{12}{Stereographic projection applied to Earth \cite {stereo_proj}.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Embedding}{12}{subsection.2.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Graph Theory}{12}{section.2.5}}
\newlabel{sec:graphs}{{2.5}{12}{Graph Theory}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Graphs}{12}{subsection.2.5.1}}
\citation{berge1973}
\citation{may1972}
\citation{berge1973}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces An example of a graph \footnotemark .\relax }}{13}{figure.caption.15}}
\@writefile{toc}{\contentsline {subsubsection}{Basic Concepts \cite  {berge1973}}{13}{figure.caption.15}}
\@writefile{toc}{\contentsline {subsubsection}{Further Specifications}{13}{Item.6}}
\citation{berge1973}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The \textbf  {Les Miserables} graph \footnotemark .\relax }}{14}{figure.caption.16}}
\newlabel{fig:graph}{{2.6}{14}{The \textbf {Les Miserables} graph \protect \footnotemark .\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces A tree extracted (a subgraph) from the \textbf  {Les Miserables} graph.\relax }}{15}{figure.caption.17}}
\newlabel{tree}{{2.7}{15}{A tree extracted (a subgraph) from the \textbf {Les Miserables} graph.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Related Problems}{16}{subsection.2.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{Nearest-Neighbor Search}{16}{subsection.2.5.2}}
\@writefile{toc}{\contentsline {paragraph}{$K$-Nearest-Neighbor Search ($K$-NN)}{16}{subsection.2.5.2}}
\@writefile{toc}{\contentsline {paragraph}{$\epsilon $-Nearest Neighbor Search ($\epsilon $-NN)}{17}{subsection.2.5.2}}
\newlabel{fig:example-graph}{{2.8a}{17}{$G$\relax }{figure.caption.18}{}}
\newlabel{sub@fig:example-graph}{{a}{17}{$G$\relax }{figure.caption.18}{}}
\newlabel{fig:example-graph-nn}{{2.8b}{17}{$G'$\relax }{figure.caption.18}{}}
\newlabel{sub@fig:example-graph-nn}{{b}{17}{$G'$\relax }{figure.caption.18}{}}
\newlabel{fig:example-graph-en}{{2.8c}{17}{$G''$\relax }{figure.caption.18}{}}
\newlabel{sub@fig:example-graph-en}{{c}{17}{$G''$\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces The original graph $G$ and the results of $K$-NN and $\epsilon $-NN, respectively.\relax }}{17}{figure.caption.18}}
\citation{cor2011}
\citation{cor2011}
\@writefile{toc}{\contentsline {subsubsection}{Single-pair Shortest-path Problem \cite  {cor2011}}{18}{figure.caption.18}}
\@writefile{toc}{\contentsline {paragraph}{Dijkstra's Algorithm}{18}{figure.caption.18}}
\citation{golin2003floydwarshall}
\newlabel{fig:spa-graph}{{2.9a}{19}{The weighted graph $G$.\relax }{figure.caption.19}{}}
\newlabel{sub@fig:spa-graph}{{a}{19}{The weighted graph $G$.\relax }{figure.caption.19}{}}
\newlabel{fig:spa-tree}{{2.9b}{19}{The shortest-path tree $S$.\relax }{figure.caption.19}{}}
\newlabel{sub@fig:spa-tree}{{b}{19}{The shortest-path tree $S$.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{All-pairs Shortest-path Problem}{19}{figure.caption.19}}
\@writefile{toc}{\contentsline {paragraph}{Floyd-Warshall Algorithm}{19}{figure.caption.19}}
\citation{pat1996}
\citation{hot2009}
\citation{pat1996}
\citation{awa2015}
\citation{awa2015}
\citation{zhu2009}
\citation{awa2015}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Machine Learning}{21}{section.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Machine Learning Algorithms}{21}{subsection.2.6.1}}
\citation{sksvm}
\citation{sksvm}
\citation{wessvmdef}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Support Vector Machine: An Example of Supervised Learning}{22}{subsection.2.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces A SVM classifier projecting a hyperplane that perfectly separates two classes of samples \cite  {sksvm}\relax }}{22}{figure.caption.20}}
\newlabel{fig:svmmargin}{{2.10}{22}{A SVM classifier projecting a hyperplane that perfectly separates two classes of samples \cite {sksvm}\relax }{figure.caption.20}{}}
\citation{wessvmdef}
\citation{mitsvm}
\newlabel{svmconst}{{2.1}{23}{Support Vector Machine: An Example of Supervised Learning}{equation.2.6.1}{}}
\newlabel{eq:eqsvmwidth}{{2.2}{23}{Support Vector Machine: An Example of Supervised Learning}{equation.2.6.2}{}}
\newlabel{eq:svmminw}{{2.3}{23}{Support Vector Machine: An Example of Supervised Learning}{equation.2.6.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{SVM for non-separable data sets (soft margins)}{23}{equation.2.6.3}}
\citation{mitsvm}
\citation{mitsvm}
\@writefile{toc}{\contentsline {subsubsection}{Dependency over the dot product}{24}{equation.2.6.3}}
\newlabel{eq:svmlag1}{{2.4}{24}{Dependency over the dot product}{equation.2.6.4}{}}
\newlabel{svmlag2}{{2.5}{24}{Dependency over the dot product}{equation.2.6.5}{}}
\newlabel{svmlag3}{{2.6}{24}{Dependency over the dot product}{equation.2.6.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Kernel functions}{24}{equation.2.6.6}}
\citation{svmkernels}
\citation{svmkernels}
\citation{svmkernels}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Projection of samples from the $\mathbb  {R}$ to the $\mathbb  {R}^2$, allowing SVM to find a hyperplane that perfectly separates both classes \cite  {svmkernels}.\relax }}{25}{figure.caption.21}}
\newlabel{fig:svmkernel}{{2.11}{25}{Projection of samples from the $\mathbb {R}$ to the $\mathbb {R}^2$, allowing SVM to find a hyperplane that perfectly separates both classes \cite {svmkernels}.\relax }{figure.caption.21}{}}
\citation{rif2008}
\citation{ovacj}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Multi-class Classification}{26}{subsection.2.6.3}}
\citation{crossvalid}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Evaluating learners}{27}{subsection.2.6.4}}
\@writefile{toc}{\contentsline {subsubsection}{Confusion Matrix}{27}{subsection.2.6.4}}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Example of confusion matrix for a data-set with four different classes.\relax }}{27}{table.caption.22}}
\@writefile{toc}{\contentsline {subsubsection}{Cross Validation}{27}{table.caption.22}}
\citation{gridsearch}
\citation{roh2015}
\citation{roh2015}
\citation{roh2015}
\@writefile{toc}{\contentsline {subsubsection}{Grid Search}{28}{table.caption.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.5}Examples of Learning}{28}{subsection.2.6.5}}
\@writefile{toc}{\contentsline {subsubsection}{Coffee Selling Rate}{28}{subsection.2.6.5}}
\citation{roh2015}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces graphic representation of a data set generalization by a linear (orange) and a nonlinear model (green) \cite  {roh2015}.\relax }}{29}{figure.caption.23}}
\newlabel{fig:rohrer2015}{{2.12}{29}{graphic representation of a data set generalization by a linear (orange) and a nonlinear model (green) \cite {roh2015}.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{Iris Flower}{29}{figure.caption.23}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Confusion matrix of a SVM with $C=100$, $gamma=.01$ and $rbf$ kernel when predicting samples from the Iris flower data set.\relax }}{29}{figure.caption.24}}
\newlabel{fig:cmsvmiris}{{2.13}{29}{Confusion matrix of a SVM with $C=100$, $gamma=.01$ and $rbf$ kernel when predicting samples from the Iris flower data set.\relax }{figure.caption.24}{}}
\@setckpt{chapters/background}{
\setcounter{page}{30}
\setcounter{equation}{6}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{7}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{6}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{13}
\setcounter{table}{4}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{float@type}{16}
\setcounter{Item}{6}
\setcounter{Hfootnote}{14}
\setcounter{bookmark@seq@number}{26}
\setcounter{lstnumber}{1}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{FancyVerbLine}{6}
\setcounter{linenumber}{1}
\setcounter{LN@truepage}{46}
\setcounter{FancyVerbLineBreakLast}{0}
\setcounter{minted@FancyVerbLineTemp}{14}
\setcounter{listing}{0}
\setcounter{theorem}{0}
\setcounter{remark}{1}
\setcounter{example}{0}
\setcounter{experiment}{0}
\setcounter{section@level}{0}
\setcounter{lstlisting}{0}
}
